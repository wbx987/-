# 基于个性化分类器的联邦学习算法研究
Client间的数据异质性是联邦学习面临的核心挑战之一。这种异质性的存在使传统的联邦平均算法（FedAvg）性能显著下降，无法达到理想效果。在此背景下，个性化联邦学习应运而生，旨在通过个性化学习策略提升算法性能。本文首先复现了经典的FedAvg算法，并在此基础上，通过引入“基础层+个性化层”的模型划分策略，复现了基于个性化分类器的联邦学习算法FedPer。该算法通过共享基础层和保留个性化层的方法，以适应客户端本地数据分布。实验结果表明，在数据高度异质环境下，FedPer算法展现出卓越的鲁棒性和稳定性，其测试准确率明显优于FedAvg，且收敛速度更快。特别是在图像复杂度更高的CIFAR-10数据集上，即使在数据极端异质的条件下，FedPer依然能够保持显著的领先优势。相比之下，FedAvg算法对数据异质性极为敏感，其性能随数据异质程度的增加而明显下降。本文的发现印证了基于个性化分类器的联邦学习算法FedPer相比于FedAvg在应对数据异质性时的优越性。

客户端数据异构性是联邦学习中的核心挑战之一。这种异构性显著降低了传统联邦平均（FedAvg）算法的性能，使其无法达到预期结果。在这种情况下，联邦学习与个性化（FL-P） emerged as a solution，通过个性化学习策略来提升算法性能。在本文中，我们首先再现了经典的 FedAvg 算法，并在此基础上构建了 FedPer，一种 Federated Learning method.ed Learning algorithm.评价学习算法基于个性化分类器，通过引入“基础+个性化”模型分区策略来适应客户端的本地数据分布，该策略共享基础层并保留个性化层以适应客户端的本地数据分布。此算法旨在适应客户端的本地数据分布。实验结果表明，FedPer算法在高度异构的数据环境中表现出色的鲁棒性和稳定性，并且其测试准确率acy 显著优于 FedAvg 并且收敛速度更快。特别是在具有更高图像复杂性的 CIFAR-10 数据集上，在极端数据异质性条件下，FedPer 仍然保持显著的领先优势。相比之下，FedAvg 算法对数据异质性非常敏感，随着数据异质性的增加，其性能显著下降。本文的发现确认了基于个性化 FedPer 联邦学习算法在解决数据异质性问题中的优越性。
